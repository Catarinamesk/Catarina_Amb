{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Catarinamesk/Catarina_Amb/blob/main/hint_pyspark_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3250cdb",
      "metadata": {
        "id": "c3250cdb"
      },
      "source": [
        "# **Exercício PySpark - Hint para Alunos**\n",
        "Este notebook fornece um ponto de partida para os alunos trabalharem com PySpark. Complete os espaços indicados para realizar as transformações, criar tabelas e consultas SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "664449b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "664449b3",
        "outputId": "9ff05453-47cb-465f-94bd-f18c6ccabbaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1. Configurar PySpark no Google Colab\n",
        "# Execute esta célula para instalar as dependências necessárias.\n",
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc42c003",
      "metadata": {
        "id": "dc42c003"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2. Importar bibliotecas\n",
        "from pyspark.sql import SparkSession\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ac0582",
      "metadata": {
        "id": "06ac0582"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. Criar a SparkSession\n",
        "# A SparkSession é o ponto de entrada para trabalhar com PySpark.\n",
        "spark = SparkSession.builder.appName(\"Hint PySpark\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a44b630",
      "metadata": {
        "id": "1a44b630"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 4. Ler o arquivo CSV em um DataFrame\n",
        "# Substitua \"sales.csv\" pelo caminho correto do arquivo que você vai usar.\n",
        "# Você pode fazer upload do arquivo manualmente no Colab e usar o caminho correspondente.\n",
        "df = spark.read.csv(\"sales.csv\", header=True, inferSchema=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ba56aa",
      "metadata": {
        "id": "d5ba56aa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 5. Exibir os dados carregados\n",
        "# Use este espaço para inspecionar os dados e entender o formato.\n",
        "# Dica: Use df.show() para visualizar os dados.\n",
        "# Exemplo:\n",
        "# df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4122eb13",
      "metadata": {
        "id": "4122eb13"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 6. Adicionar uma transformação no DataFrame\n",
        "# Aqui, você deve aplicar um filtro ou transformação nos dados carregados.\n",
        "# Exemplo: Filtrar vendas acima de um valor específico.\n",
        "# Substitua este espaço com sua transformação.\n",
        "# vendas_filtradas = df.filter(df[\"TotalPrice\"] > 500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afae41ab",
      "metadata": {
        "id": "afae41ab"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 7. Criar uma tabela temporária\n",
        "# Registre o DataFrame como uma tabela temporária para realizar consultas SQL.\n",
        "# Exemplo:\n",
        "# df.createOrReplaceTempView(\"sales\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6609e7ee",
      "metadata": {
        "id": "6609e7ee"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 8. Executar uma consulta SQL\n",
        "# Escreva uma consulta para sumarizar ou filtrar os dados na tabela.\n",
        "# Exemplo:\n",
        "# resultado = spark.sql(\"SELECT Region, SUM(TotalPrice) AS TotalRevenue FROM sales GROUP BY Region\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ff29752",
      "metadata": {
        "id": "0ff29752"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 9. Exibir o resultado final\n",
        "# Mostre os resultados da consulta ou transformação para verificar se está correto.\n",
        "# Exemplo:\n",
        "# resultado.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}